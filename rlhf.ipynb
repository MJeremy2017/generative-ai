{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc74e33c-e6a9-4f9f-9020-e5853dddb716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q peft==0.3.0 trl==0.4.4 transformers==4.27.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41041ffc-b89a-4480-8877-3e1193260a6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RL Train Model to Make it less Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d693c0bc-e153-4c33-8471-eb79f092320f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 09:35:12.618769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-03 09:35:17.648250: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-03 09:35:24.722122: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-06-03 09:35:24.722266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-06-03 09:35:24.722276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Could not load bitsandbytes native library: /usr/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda126.so)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
      "    lib = get_native_library()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n",
      "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
      "  File \"/opt/conda/lib/python3.10/ctypes/__init__.py\", line 452, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/opt/conda/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: /usr/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda126.so)\n",
      "\n",
      "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
      "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
      "and open an issue at: https://github.com/bitsandbytes-foundation/bitsandbytes/issues\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c98832-a46e-4015-bd30-0292f4029661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "original_dataset = load_dataset(dataset_name)\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c819909-19d9-4594-87b1-f11bd7aba102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(model_name, ds_name, min_length, max_length):\n",
    "    dataset = load_dataset(ds_name)\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "    dataset = dataset.filter(\n",
    "        lambda x: len(x[\"dialogue\"]) <= max_length and len(x[\"dialogue\"]) >= min_length, num_proc=2)\n",
    "    # auto switch between GPU and CPU\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following text.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        # query is required from PPO trainer\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "    \n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=123)\n",
    "    return dataset_splits    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bd16e8-3561-4d4b-bdfd-21bd1e9d91a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
       "        num_rows: 8018\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
       "        num_rows: 2005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = build_dataset(model_name, dataset_name, 200, 1000)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a146715-29a6-4625-85e1-12fddca0ca48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following text. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You told me that you had some musical talent, right? #Person2#: Yes, I'm a singer. #Person1#: Perfect. So you can audition this weekend here at my house. #Person2#: Great! Wait here? You don't have enough room for the amplifiers, microphones or even your drums! By the way where do you keep them or practice? Summary: </s> tensor([12198,  1635,  1737,     8,   826,  1499,     5,  1713,   345, 13515,\n",
      "          536,  4663,    10,    27,    31,    51,     3, 10454,     3,     9,\n",
      "          723,  1928,     5,  1713,   345, 13515,   357,  4663,    10,   531,\n",
      "           25,   641,   214,   149,    12,   577,    46,  5009,    58,  1713,\n",
      "          345, 13515,   536,  4663,    10,   412,   107,     5,     3,     5,\n",
      "            3,     5, 11475,    55,    27,    31,   553,    15,  1219,    25,\n",
      "            3,     9,  7863,   648,    24,    27,    31,    51,  1036,    12,\n",
      "          577,     8,  5253,     7,     5,   852,    24,    27,   214,   149,\n",
      "           12,   577,   168,     6,    27,   133,   114,    12,   607,     3,\n",
      "            9,  2480,  1928,     5,  1713,   345, 13515,   357,  4663,    10,\n",
      "           71,  1583,    45,   909,     6,   113,    33,     8,   119,   724,\n",
      "           13,     8,  1928,    58,  1713,   345, 13515,   536,  4663,    10,\n",
      "          101,    43,     3,     9,  4024,   113,  4805,  5507,     6,    11,\n",
      "          430,   113,  4805,  7981,     5,  1875,    62,   341,    43,    29,\n",
      "           31,    17,   435,  1321,    12,    36,    69,  7634,     5,   148,\n",
      "         1219,   140,    24,    25,   141,   128,  4183,  3683,     6,   269,\n",
      "           58,  1713,   345, 13515,   357,  4663,    10,  2163,     6,    27,\n",
      "           31,    51,     3,     9,  7634,     5,  1713,   345, 13515,   536,\n",
      "         4663,    10,  7710,     5,   264,    25,    54, 21042,    48,  1851,\n",
      "          270,    44,    82,   629,     5,  1713,   345, 13515,   357,  4663,\n",
      "           10,  1651,    55, 14583,   270,    58,   148,   278,    31,    17,\n",
      "           43,   631,   562,    21,     8, 22325,     7,     6, 18701,     7,\n",
      "           42,   237,    39,  5253,     7,    55,   938,     8,   194,   213,\n",
      "          103,    25,   453,   135,    42,  1032,    58, 20698,    10,     3,\n",
      "            1])\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "q = dataset[\"test\"][\"query\"][idx]\n",
    "input_ids = dataset[\"test\"][\"input_ids\"][idx]\n",
    "\n",
    "print(q, input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be32e4-726c-4b4a-b975-95b748f876c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c972020-128a-44bc-83b5-4e811654439e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_params(model):\n",
    "    all_model_params = 0\n",
    "    trainable_params = 0\n",
    "    for param in model.parameters():\n",
    "        cnt = param.numel()\n",
    "        all_model_params += cnt\n",
    "        if param.requires_grad:\n",
    "            trainable_params += cnt \n",
    "    print(f\"trainable params: {trainable_params}, % of trainable params {trainable_params*100/all_model_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7bc9f9-5ee3-45c7-870e-30ca36c9a19f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 247577856, % of trainable params 100.00%\n"
     ]
    }
   ],
   "source": [
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "print_trainable_params(original_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0164b25-37c2-45da-9cd8-528d0545e544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3538944, % of trainable params 1.41%\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(\n",
    "    original_model, \n",
    "    config,\n",
    ")\n",
    "\n",
    "print_trainable_params(lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2673a-bb81-4eef-95c5-4b16e1f090bc",
   "metadata": {},
   "source": [
    "# PPO Model\n",
    "\n",
    "During PPO training, there's only a few parameters are updated. Specifically, the `ValueHead` which has `(n+1) * m`, where `n` is the number of input parameters, which is `768` here and `m` is the number of output unit, which is `1` in this case. The extra `n+1` is the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8966cb-b196-4bc8-87ef-5a236ffa94d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3539713, % of trainable params 1.41%\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(\n",
    "    lora_model,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    is_trainable=True\n",
    ")\n",
    "\n",
    "print_trainable_params(ppo_model)\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e63dbc6-8013-4ad3-b582-7809a031b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frozen model for calculating the KL divergence\n",
    "reference_model = create_reference_model(ppo_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959143b-bd90-431c-80d4-b50b00f45510",
   "metadata": {},
   "source": [
    "# Reward Model\n",
    "\n",
    "Here we're preloading a already trained hate-speech model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd313921-bcba-4517-915f-a23d990798a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'nothate', 1: 'hate'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac104ab-2107-4600-a2b0-543238312760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def toxicity_reward(text):\n",
    "    input_ids = toxicity_tokenizer.encode(text, return_tensors=\"pt\").to(toxicity_model.device)\n",
    "    logits = toxicity_model(input_ids=input_ids).logits\n",
    "\n",
    "    print(\"logits [nothate, hate]:\", logits.tolist())\n",
    "\n",
    "    probs = logits.softmax(dim=-1).tolist()\n",
    "    print(\"probabilities:\", probs)\n",
    "\n",
    "    nothate_index = 0\n",
    "    reward = logits[:, nothate_index].tolist()\n",
    "    print(\"reward:\", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24a45674-4fc5-4969-8038-eadd24b78577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [nothate, hate]: [[4.657958030700684, -4.078615188598633]]\n",
      "probabilities: [[0.9998394250869751, 0.00016057751781772822]]\n",
      "reward: [4.657958030700684]\n",
      "logits [nothate, hate]: [[-2.5696704387664795, 2.2942163944244385]]\n",
      "probabilities: [[0.0076612685807049274, 0.9923386573791504]]\n",
      "reward: [-2.5696704387664795]\n"
     ]
    }
   ],
   "source": [
    "non_toxic_texts = \"I want to kiss you\"\n",
    "toxicity_reward(non_toxic_texts)\n",
    "\n",
    "toxic_texts = \"hate hate hate hate hate damn damn, disgusting, damn, damn\"\n",
    "toxicity_reward(toxic_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14ea63-a79d-4b7f-b458-6e7c4cdf3423",
   "metadata": {},
   "source": [
    "# Evaluator\n",
    "\n",
    "We need to evaluate the toxicity score before and after RL the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb0850b-6ef3-4854-b65d-8248389d1499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxicity_evaluator = evaluate.load(\n",
    "    \"toxicity\",  # the module must exist on the Hub\n",
    "    toxicity_model_name,\n",
    "    module_type=\"measurement\",\n",
    "    toxic_label=\"hate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c687bdc-b201-4a66-9ab3-a523a8f573a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxicity': [0.00016057782340794802, 0.9923386573791504]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_evaluator.compute(predictions=[non_toxic_texts, toxic_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdba2f8e-e20c-4351-9d91-2d035fb6d372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model, dataset, evaluator, tokenizer, num_samples=100, device=\"cuda:0\"):\n",
    "    scores = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        input_texts = sample[\"query\"]\n",
    "        input_ids = tokenizer(input_texts, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "        \n",
    "        gen_config = GenerationConfig(\n",
    "            top_k=0.0,\n",
    "            top_p=1.,\n",
    "            max_new_tokens=100\n",
    "        )\n",
    "        response = model.generate(input_ids.squeeze(), generation_config=gen_config)\n",
    "        \n",
    "        generated_texts = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "        score = evaluator.compute(predictions=[input_texts + \" \" + generated_texts])[\"toxicity\"][0]\n",
    "        scores.append(score)\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a00f894-546f-464a-bbf1-824bad3f71fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:10,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.013254199677612632, 0.017038578291544454)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "model_base = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "evaluate_toxicity(model_base, dataset[\"test\"], toxicity_evaluator, tokenizer, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868c2c1-4452-4c97-b878-eef1727b7ee6",
   "metadata": {},
   "source": [
    "# PPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45b4bed1-c9d6-48d8-aa99-33ffd4e9eb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 0.9998394250869751}]\n",
      "[{'label': 'hate', 'score': 0.9923386573791504}]\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=toxicity_model_name, device=\"cuda:0\")\n",
    "print(sentiment_pipe(non_toxic_texts))\n",
    "print(sentiment_pipe(toxic_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45759ea4-3161-4563-9e6d-00afef491687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "epoch = 1\n",
    "mini_batch_size = 4\n",
    "batch_size = 16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=lr,\n",
    "    ppo_epochs=epoch,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "    \n",
    "    \n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=config,\n",
    "    model=ppo_model,\n",
    "    ref_model=reference_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset[\"train\"],\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cc2df-a951-4b88-9c0b-89365a2d6881",
   "metadata": {},
   "source": [
    "# Training Step\n",
    "\n",
    "- Get response from the `PEFT` model.\n",
    "- Use our reward model to score it.\n",
    "- `PPO` uses the `(query, response, reward)` to step update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c93bd8a8-7662-457f-af7c-84e92d033409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:11, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.01323603093624115\n",
      "ppo/returns/mean: 0.5735414028167725\n",
      "ppo/policy/advantages_mean: 3.6600368957806495e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:24, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.0010002406779676676\n",
      "ppo/returns/mean: 0.5440765619277954\n",
      "ppo/policy/advantages_mean: -4.0404074752586894e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:38, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.018401362001895905\n",
      "ppo/returns/mean: 0.5329046249389648\n",
      "ppo/policy/advantages_mean: 3.989992336528303e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:48, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.023309554904699326\n",
      "ppo/returns/mean: 0.6544452905654907\n",
      "ppo/policy/advantages_mean: 4.727026947648483e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:58, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.000607750378549099\n",
      "ppo/returns/mean: 0.6480923891067505\n",
      "ppo/policy/advantages_mean: -4.554198085315875e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "6it [01:09, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.0034901639446616173\n",
      "ppo/returns/mean: 0.5957009792327881\n",
      "ppo/policy/advantages_mean: 1.454697251546122e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:20, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.011727528646588326\n",
      "ppo/returns/mean: 0.6230140328407288\n",
      "ppo/policy/advantages_mean: 3.69170365388527e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:31, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.02266332507133484\n",
      "ppo/returns/mean: 0.6189992427825928\n",
      "ppo/policy/advantages_mean: -4.4404227850236566e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:42, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.0060292379930615425\n",
      "ppo/returns/mean: 0.6026135087013245\n",
      "ppo/policy/advantages_mean: 1.622104832676996e-07\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:54, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.012080973014235497\n",
      "ppo/returns/mean: 0.5679567456245422\n",
      "ppo/policy/advantages_mean: -3.1678041523264255e-08\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_length = 100\n",
    "max_length = 400\n",
    "length_sampler = LengthSampler(min_length, max_length)  # just a random sampler within range\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None,  # return all scores\n",
    "    \"function_to_apply\": None,  # return logits\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "    summary_tensors = []\n",
    "    \n",
    "    for prompt in prompt_tensors:\n",
    "        length = length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = length\n",
    "        \n",
    "        summary = ppo_trainer.generate(prompt, **generation_kwargs)\n",
    "        summary_tensors.append(summary.squeeze()[-length:])\n",
    "    # it must name response\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "    query_response_pairs = [q+r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    \n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "    reward_tensors = [torch.tensor(r[0][\"score\"]) for r in rewards]\n",
    "    \n",
    "    stats = ppo_trainer.step(\n",
    "        queries=prompt_tensors, \n",
    "        responses=summary_tensors, \n",
    "        scores=reward_tensors\n",
    "    )\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    print(\"objective/kl:\", stats[\"objective/kl\"])\n",
    "    print(\"ppo/returns/mean:\", stats[\"ppo/returns/mean\"])\n",
    "    print(\"ppo/policy/advantages_mean:\", stats[\"ppo/policy/advantages_mean\"])\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3d6ca-9f20-4758-8a2f-0e48992cd45d",
   "metadata": {},
   "source": [
    "# Evaluate Quantitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f4e9425-62aa-4944-a24f-fca35351e909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.013254199677612632, 0.017038578291544454)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_toxicity(ppo_trainer, dataset[\"test\"], toxicity_evaluator, tokenizer, num_samples=10, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c0c22-c149-45a8-9923-34ef16882f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd23291-a679-407d-9db5-b156e728d03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
