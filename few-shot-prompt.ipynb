{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch torchdata transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136c2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3a7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cdce8f",
   "metadata": {},
   "source": [
    "# Human Labelled Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4570a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#Person1#: Did Bean send these dirty jokes to you, too? Look!\n",
      "#Person2#: What a creep! Phony good luck e-mails are one thing, but sexual harassment is crossing the line.\n",
      "#Person1#: No wonder he asked for my address first-he just wants to harass me!\n",
      "#Person2#: You could try using a spam filter to reject stuff that's obviously pornographic or anything else you don't want.\n",
      "Human summary:\n",
      "#Person2# suggests #Person1# use a spam filter to reject Bean's pornographic stuff.\n",
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#Person1#: May I take your order?\n",
      "#Person2#: We haven't decided yet. Could you give us a little longer?\n",
      "#Person1#: Yes, take your time, please.\n",
      "#Person2#: Can we get something to drink? We want two bottles of beer.\n",
      "#Person1#: Fine.\n",
      "#Person2#: Could you tell us your specials today?\n",
      "#Person1#: The special today is steak.\n",
      "#Person2#: We'll take this steak dinner.\n",
      "#Person1#: What would you like to go with your steak?\n",
      "#Person2#: Peas and carrots.\n",
      "#Person1#: I see. What would you like for dessert?\n",
      "#Person2#: Icecream, please.\n",
      "Human summary:\n",
      "#Person1# serves #Person2# to order two bottles of beer, a steak dinner, and ice cream.\n"
     ]
    }
   ],
   "source": [
    "example_indices = [12, 30]\n",
    "seg = \"-\" * 100\n",
    "for ind in example_indices:\n",
    "    print(\"Dialogue:\")\n",
    "    print(seg)\n",
    "    print(dataset[\"train\"][\"dialogue\"][ind])\n",
    "    print(\"Human summary:\")\n",
    "    print(dataset[\"train\"][\"summary\"][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f093fb",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bbedacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad30f684fb594d3eb6c87ddcf070aba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699eb47732a044d3a952e91a8652c74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc1eee969044eb3af0dcce1d547f7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0c976b5f5f4eaf99d7b3ed0d26a4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff102d724604274a978573723ff8d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36cf99ac3494e7da662d3158778075a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ae99954ee04d7b86d627be4fbc1b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c8358",
   "metadata": {},
   "source": [
    "# Sentence Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "978e4413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#Person1#: Did Bean send these dirty jokes to you, too? Look!\n",
      "#Person2#: What a creep! Phony good luck e-mails are one thing, but sexual harassment is crossing the line.\n",
      "#Person1#: No wonder he asked for my address first-he just wants to harass me!\n",
      "#Person2#: You could try using a spam filter to reject stuff that's obviously pornographic or anything else you don't want.\n",
      "AI Completion:\n",
      "Bean is a sexy person, but he doesn't want to harass you\n",
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "#Person1#: May I take your order?\n",
      "#Person2#: We haven't decided yet. Could you give us a little longer?\n",
      "#Person1#: Yes, take your time, please.\n",
      "#Person2#: Can we get something to drink? We want two bottles of beer.\n",
      "#Person1#: Fine.\n",
      "#Person2#: Could you tell us your specials today?\n",
      "#Person1#: The special today is steak.\n",
      "#Person2#: We'll take this steak dinner.\n",
      "#Person1#: What would you like to go with your steak?\n",
      "#Person2#: Peas and carrots.\n",
      "#Person1#: I see. What would you like for dessert?\n",
      "#Person2#: Icecream, please.\n",
      "AI Completion:\n",
      "What would you like for dessert?\n"
     ]
    }
   ],
   "source": [
    "example_indices = [12, 30]\n",
    "seg = \"-\" * 100\n",
    "for ind in example_indices:\n",
    "    print(\"Dialogue:\")\n",
    "    print(seg)\n",
    "    input_sentence = dataset[\"train\"][\"dialogue\"][ind]\n",
    "    print(input_sentence)\n",
    "    print(\"AI Completion:\")\n",
    "    encoded = tokenizer(input_sentence, return_tensors=\"pt\")\n",
    "    out = model.generate(**encoded)\n",
    "    decoded_sentence = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b647529",
   "metadata": {},
   "source": [
    "# Prompt to Ask for Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65edef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Summarise the following dialogue:\n",
      "------\n",
      "#Person1#: Did Bean send these dirty jokes to you, too? Look!\n",
      "#Person2#: What a creep! Phony good luck e-mails are one thing, but sexual harassment is crossing the line.\n",
      "#Person1#: No wonder he asked for my address first-he just wants to harass me!\n",
      "#Person2#: You could try using a spam filter to reject stuff that's obviously pornographic or anything else you don't want.\n",
      "    \n",
      "AI Summary:\n",
      "Bean is a sexy guy.\n",
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Summarise the following dialogue:\n",
      "------\n",
      "#Person1#: May I take your order?\n",
      "#Person2#: We haven't decided yet. Could you give us a little longer?\n",
      "#Person1#: Yes, take your time, please.\n",
      "#Person2#: Can we get something to drink? We want two bottles of beer.\n",
      "#Person1#: Fine.\n",
      "#Person2#: Could you tell us your specials today?\n",
      "#Person1#: The special today is steak.\n",
      "#Person2#: We'll take this steak dinner.\n",
      "#Person1#: What would you like to go with your steak?\n",
      "#Person2#: Peas and carrots.\n",
      "#Person1#: I see. What would you like for dessert?\n",
      "#Person2#: Icecream, please.\n",
      "    \n",
      "AI Summary:\n",
      "What would you like for dessert?\n"
     ]
    }
   ],
   "source": [
    "example_indices = [12, 30]\n",
    "seg = \"-\" * 100\n",
    "for ind in example_indices:\n",
    "    template = f\"\"\"\n",
    "Summarise the following dialogue:\n",
    "------\n",
    "{dataset[\"train\"][\"dialogue\"][ind]}\n",
    "    \"\"\"\n",
    "    print(\"Dialogue:\")\n",
    "    print(seg)\n",
    "    print(template)\n",
    "    encoded = tokenizer.encode(template, return_tensors=\"pt\")\n",
    "    output = model.generate(encoded)\n",
    "    output_sentence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"AI Summary:\")\n",
    "    print(output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca172e5c",
   "metadata": {},
   "source": [
    "# 1, 2, Few Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2c21095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "#Person1#: May I take your order?\n",
      "#Person2#: We haven't decided yet. Could you give us a little longer?\n",
      "#Person1#: Yes, take your time, please.\n",
      "#Person2#: Can we get something to drink? We want two bottles of beer.\n",
      "#Person1#: Fine.\n",
      "#Person2#: Could you tell us your specials today?\n",
      "#Person1#: The special today is steak.\n",
      "#Person2#: We'll take this steak dinner.\n",
      "#Person1#: What would you like to go with your steak?\n",
      "#Person2#: Peas and carrots.\n",
      "#Person1#: I see. What would you like for dessert?\n",
      "#Person2#: Icecream, please.\n",
      "\n",
      "#Person1# serves #Person2# to order two bottles of beer, a steak dinner, and ice cream.\n",
      "\n",
      "Now Summarise the following dialogue:\n",
      "\n",
      "#Person1#: Did Bean send these dirty jokes to you, too? Look!\n",
      "#Person2#: What a creep! Phony good luck e-mails are one thing, but sexual harassment is crossing the line.\n",
      "#Person1#: No wonder he asked for my address first-he just wants to harass me!\n",
      "#Person2#: You could try using a spam filter to reject stuff that's obviously pornographic or anything else you don't want.\n",
      "\n",
      "AI Summary:\n",
      "Bean is a sexy guy.\n"
     ]
    }
   ],
   "source": [
    "seg = \"-\" * 100\n",
    "\n",
    "input_sentence = dataset[\"train\"][\"dialogue\"][30]\n",
    "human_summary = dataset[\"train\"][\"summary\"][30]\n",
    "to_summarise = dataset[\"train\"][\"dialogue\"][12]\n",
    "template = f\"\"\"\n",
    "{input_sentence}\n",
    "\n",
    "{human_summary}\n",
    "\n",
    "Now Summarise the following dialogue:\n",
    "\n",
    "{to_summarise}\n",
    "\"\"\"\n",
    "print(\"Dialogue:\")\n",
    "print(seg)\n",
    "print(template)\n",
    "encoded = tokenizer.encode(template, return_tensors=\"pt\")\n",
    "output = model.generate(encoded)\n",
    "output_sentence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"AI Summary:\")\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b8bd1",
   "metadata": {},
   "source": [
    "# Config Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "511f1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "#Person1#: May I take your order?\n",
      "#Person2#: We haven't decided yet. Could you give us a little longer?\n",
      "#Person1#: Yes, take your time, please.\n",
      "#Person2#: Can we get something to drink? We want two bottles of beer.\n",
      "#Person1#: Fine.\n",
      "#Person2#: Could you tell us your specials today?\n",
      "#Person1#: The special today is steak.\n",
      "#Person2#: We'll take this steak dinner.\n",
      "#Person1#: What would you like to go with your steak?\n",
      "#Person2#: Peas and carrots.\n",
      "#Person1#: I see. What would you like for dessert?\n",
      "#Person2#: Icecream, please.\n",
      "\n",
      "#Person1# serves #Person2# to order two bottles of beer, a steak dinner, and ice cream.\n",
      "\n",
      "Now Summarise the following dialogue:\n",
      "\n",
      "#Person1#: Did Bean send these dirty jokes to you, too? Look!\n",
      "#Person2#: What a creep! Phony good luck e-mails are one thing, but sexual harassment is crossing the line.\n",
      "#Person1#: No wonder he asked for my address first-he just wants to harass me!\n",
      "#Person2#: You could try using a spam filter to reject stuff that's obviously pornographic or anything else you don't want.\n",
      "\n",
      "AI Summary:\n",
      "Bean is a sexy guy. He's a sexy guy.\n"
     ]
    }
   ],
   "source": [
    "seg = \"-\" * 100\n",
    "\n",
    "input_sentence = dataset[\"train\"][\"dialogue\"][30]\n",
    "human_summary = dataset[\"train\"][\"summary\"][30]\n",
    "to_summarise = dataset[\"train\"][\"dialogue\"][12]\n",
    "template = f\"\"\"\n",
    "{input_sentence}\n",
    "\n",
    "{human_summary}\n",
    "\n",
    "Now Summarise the following dialogue:\n",
    "\n",
    "{to_summarise}\n",
    "\"\"\"\n",
    "print(\"Dialogue:\")\n",
    "print(seg)\n",
    "print(template)\n",
    "\n",
    "\n",
    "config = GenerationConfig(max_new_tokens=100, min_new_tokens=20, temperature=0.2, top_k=100)\n",
    "encoded = tokenizer.encode(template, return_tensors=\"pt\")\n",
    "output = model.generate(encoded, generation_config=config)\n",
    "output_sentence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"AI Summary:\")\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8320a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
