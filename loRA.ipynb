{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f67376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate==0.4.0 rouge_score==0.1.2 loralib==0.1.1 peft==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f18683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch, time\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcba3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e137386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_params(model):\n",
    "    all_model_params = 0\n",
    "    trainable_params = 0\n",
    "    for param in model.parameters():\n",
    "        cnt = param.numel()\n",
    "        all_model_params += cnt\n",
    "        if param.requires_grad:\n",
    "            trainable_params += cnt \n",
    "    print(f\"trainable params: {trainable_params}, % of trainable params {trainable_params*100/all_model_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a1f341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 247577856, % of trainable params 100.00%\n"
     ]
    }
   ],
   "source": [
    "print_trainable_params(original_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c072fa",
   "metadata": {},
   "source": [
    "# Zero Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b6a10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "====================================================================================================\n",
      "\n",
      "Summarise the following conversation:\n",
      "---\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "    \n",
      "Model inference:\n",
      "====================================================================================================\n",
      "#Person1#: I'm thinking of upgrading my computer.\n",
      "Human summary:\n",
      "====================================================================================================\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
     ]
    }
   ],
   "source": [
    "example_indices = [200]\n",
    "sep = \"=\" * 100\n",
    "for ind in example_indices:\n",
    "    text = dataset[\"test\"][\"dialogue\"][ind]\n",
    "    human_label = dataset[\"test\"][\"summary\"][ind]\n",
    "    tmp = f\"\"\"\n",
    "Summarise the following conversation:\n",
    "---\n",
    "{text}\n",
    "    \"\"\"\n",
    "    print(\"Input:\")\n",
    "    print(sep)\n",
    "    print(tmp)\n",
    "    inputs = tokenizer(tmp, return_tensors=\"pt\")\n",
    "    output = original_model.generate(**inputs)\n",
    "    output_decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"Model inference:\")\n",
    "    print(sep)\n",
    "    print(output_decoded)\n",
    "    \n",
    "    print(\"Human summary:\")\n",
    "    print(sep)\n",
    "    print(human_label)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6df46",
   "metadata": {},
   "source": [
    "# Full Instruction Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6496a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(rows):\n",
    "    prompt_template = \"Summarise the following prompt:\\n{}\\nSummary:\"\n",
    "    texts = [prompt_template.format(d) for d in rows[\"dialogue\"]]\n",
    "    inputs = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    targets = tokenizer(rows[\"summary\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    # set -100 to padding tokens, which will be ignored by T5 during loss calculation\n",
    "    inputs[\"labels\"] = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in labels]\n",
    "        for labels in targets[\"input_ids\"]\n",
    "    ]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f34966f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset = dataset.filter(lambda row, index: index % 100 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b811cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8209c567ae174ac3a160ec37cfec1614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8da85cc9c043fab5af3044a7aed8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979e8a32aab04d6e97191a7c79e655b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLY use 125 training examples\n",
    "tokenized_dataset = sub_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba08fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"lora-summary-train-logs\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    per_device_eval_batch_size=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=original_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "570d3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOM on CPU\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf3834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
